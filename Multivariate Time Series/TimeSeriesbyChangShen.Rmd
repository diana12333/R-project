---
title: "TimeSeriesbyChangShen"
author: "ChangShen"
date: "10/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir="/Users/dianshen/Library/Mobile Documents/com~apple~CloudDocs/19Fall/TimeSeriesinR:Python/Project/")
```

##load package
```{r load package}
if(!"pacman" %in%installed.packages()) install.packages("pacman")
library(pacman)
p_load(readr,dplyr,tidyr,ggplot2,ggthemes,ggthemr,Hmisc,forecast,fpp2,zoo,astsa,ggmap,imputeTS,tseries,TSA,ggfortify,sf,caschrono,mapview,vars,tidyquant,plotly,seastests,fastDummies)
```

## Describe data set
```{r pressure}
#[1] "Date"         "Location"     "MinTemp"      "MaxTemp"      "Rainfall"     "WindSpeed9am" "WindSpeed3pm" "Humidity9am" 
# [9] "Humidity3pm"  "Pressure9am"  "Pressure3pm"  "Temp9am"      "Temp3pm"      "RainToday"    "RISK_MM"      "RainTomorrow"
ts_au<-read_csv("weatherAUS 3.csv")
ts_au<-ts_au%>%select(-c("Cloud3pm","Cloud9am","WindDir9am","WindDir3pm","WindGustSpeed","WindGustDir","Sunshine","Evaporation"))%>%filter(!Location %in% c("Nhil","Uluru","NorfolkIsland"))

ts_au_max <- ts_au%>%group_by(Location)%>%
    dplyr::summarise(max=max(Date),min=min(Date))
timeframe<-data.frame(Date=seq(as.Date(max(ts_au_max$min)),as.Date(max(ts_au_max$max)),by = 1))
location.au<-data.frame(Location=unique(ts_au$Location))
timeframe<-merge(timeframe,location.au)
ts_au <- timeframe%>%left_join(ts_au,by=c("Date","Location"))

#write_csv(ts_au[,c("Date","Location","MaxTemp","MinTemp","Rainfall", "WindSpeed9am","WindSpeed3pm","Humidity9am","Humidity3pm","Pressure9am","Pressure3pm")], "ts_au.csv")

pathname<-"/Users/dianshen/Library/Mobile Documents/com~apple~CloudDocs/19Fall/TimeSeriesinR:Python/Project/"
#fill all missing data with ImputeTS
ts_au <-read_csv(paste(pathname,"ts_au.csv", sep = ""))
describe(ts_au)
latex(describe(ts_au))
```

```{r geological data}
ts_au_missing <- ts_au%>%group_by(Location)%>%
  dplyr::summarise(na=sum(is.na(MaxTemp)))%>%arrange(desc(na))
register_google(key = "xxxxxxxx")
lonlat<-data.frame(Location=unique(ts_au$Location))
lonlat$Location<-paste("Australia",as.character(lonlat$Location))
lonlat<-mutate_geocode(lonlat,Location)
# save the result for convenience
#write_csv(lonlat,paste(pathname,"lonlat.csv",sep = ""))

ts_au_temp<-ts_au%>%mutate(Location = paste("Australia",as.character(Location)))%>%filter(Date==as.Date("2015-11-18"))%>%
  dplyr::select(Location,MaxTemp)
lonlat <-lonlat%>%left_join(ts_au_temp,by="Location")
#locations_sf <- st_as_sf(lonlat, coords = c("lon", "lat"), crs = 4326)
#mapview(locations_sf)


```

```{r time series}
ts_au_sydney<-ts_au[which(ts_au$Location=="Sydney"),c("Date","MaxTemp","MinTemp", "WindSpeed9am","WindSpeed3pm","Humidity9am","Humidity3pm","Pressure9am","Pressure3pm")]
ts_au_sydney<-ts_au_sydney%>%mutate(date=Date)%>%
  separate(date,into = c("year","month","date"),sep="-")%>%
  mutate(Month = month)%>%
  unite("monthday",month:date,sep="-")
ts_au_sydney[,2:9]<-apply(ts_au_sydney[,2:9],2,na_interpolation,type = "spline")
ts_au_sydney2<-zoo((ts_au_sydney[,-c(1,10:12)]),as.Date(ts_au_sydney$Date))

p1 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),MaxTemp))+geom_line()+geom_point()+geom_smooth()+ggtitle("Maxtemp time series")+xlab("Date")
p2 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),MinTemp))+geom_line()+geom_point()+geom_smooth()+ggtitle("Mintemp time series")+xlab("Date")
p3 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),WindSpeed9am))+geom_line()+geom_point()+geom_smooth()+ggtitle("WindSpeed9am time series")+xlab("Date")
p4 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),WindSpeed3pm))+geom_line()+geom_point()+geom_smooth()+ggtitle("WindSpeed3pm time series")+xlab("Date")
p5 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),Humidity9am))+geom_line()+geom_point()+geom_smooth()+ggtitle("Humidity9am time series")+xlab("Date")
p6 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),Humidity3pm))+geom_line()+geom_point()+geom_smooth()+ggtitle("Humidity3pm time series")+xlab("Date")
p7 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),Pressure9am))+geom_line()+geom_point()+geom_smooth()+ggtitle("Pressure9am time series")+xlab("Date")
p8 <- ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$Date),Pressure3pm))+geom_line()+geom_point()+geom_smooth()+ggtitle("Pressure3pm time series")+xlab("Date")

grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,ncol=2)


ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$monthday,"%m-%d"),MaxTemp,color = year))+geom_line()+geom_point()
ggplot(ts_au_sydney,aes(as.Date(ts_au_sydney$monthday,"%m-%d"),MaxTemp,color = year))+geom_line()+geom_point()+facet_grid(year~.)


adf.test(ts_au_sydney2$MaxTemp)
```


# 1.check whether there are missing value
# 2. using linear interpolation
# 3. exam on the outlier 
# 4. plot the time series data/ line and calendar heat map(cite) 
# 5. check the seasonality -> find the period using the periodigram(in case there are multiple periods)
# 6. check the stationary -> stationary we don't need to conduct the normal difference/but we need to conduct the seasonal difference
# 7. plot the acf and pacf -> use to roughly decide order of sarima

```{r missing_value_imputation_and_outlier_examination}
statsNA(ts_au_sydney$MaxTemp)

#Max_temp_ts<-zoo(ts_au_sydney$MaxTemp,as.Date(ts_au_sydney$Date), frequency = 365)
Max_temp_ts <- ts(ts_au_sydney$MaxTemp,frequency = 365.25, start = c(2013,3,1), end = c(2017,6,25))
outlier_ts<-tsoutliers(Max_temp_ts); outlier_ts

#ggtsdiag(fit1)
adf.test(Max_temp_ts)
ggtsdisplay(Max_temp_ts, lag.max = 500, main = "Max Temperature")+ ggtitle("Max Temperature")
ggtsdisplay(diff(Max_temp_ts, lag = 365), lag.max = 500)
```

1.take 2 difference to elimnate the seasonal 
tests to confirm normality
absence of serial correlation
absence of heteroscedasticity
$$
norm\_corr(x,y)=\dfrac{\sum_{n=0}^{n-1} x[n]*y[n]}{\sqrt{\sum_{n=0}^{n-1} x[n]^2 * \sum_{n=0}^{n-1} y[n]^2}}
$$
```{r}
library(vars)
ts_au_pre2 <- diff(ts_au_pre,lag=365) 
ts_au_pre <-as.ts(ts_au_sydney[,2:9],frequency = 365.25, start = c(2013,3,1), end = c(2017,6,25))
VARselect(ts_au_pre,type = "const", season = 365)
var1<-VAR(ts_au_pre,p=1,type = "const", season = NULL, ic ="AIC") 
var1.serial<-serial.test(var1, lags.pt=10, type="PT.asymptotic");var1.serial
plot(var1.serial)
plot(forecast(var1,h=365))

var2<-VAR(ts_au_pre,p=1,type = "const", season = 365, ic ="AIC") 
var2.serial<-serial.test(var2, lags.pt=10, type="PT.asymptotic");var2.serial
plot(var2.serial)
plot(forecast(var2,h=365))

var3<-VAR(ts_au_pre,p=2,type = "const", season = NULL, ic ="AIC") 
var3.serial<-serial.test(var3, lags.pt=10, type="PT.asymptotic");var3.serial
plot(var3.serial)
plot(forecast(var3,h=365))

var4<-VAR(ts_au_pre,p=4,type = "const", season = NULL, ic ="AIC") 
var4.serial<-serial.test(var4, lags.pt=10, type="PT.asymptotic");var4.serial
plot(var4.serial)
plot(forecast(var4,h=365))

results <- fastDummies::dummy_cols(ts_au_sydney[,-c(1,10:11)], select_columns = "Month")
ts_au_pre <-as.ts(results[1:1300,-c(9,20)], start = c(2013,3,1), end = c(2017,6,25))
ts_au_pre_test <-as.ts(results[1301:1578,-c(9,20)], start = c(2013,3,1), end = c(2017,6,25))
var5<-VAR(ts_au_pre,p=1,type = "const", season = NULL, ic ="AIC") 
var5.serial<-serial.test(var5, lags.pt=10, type="PT.asymptotic");var5.serial
plot(var5.serial)
plot(forecast(var5,h=365))
```
```{r}
acf <- acf2(diff(Max_temp_ts, lag = 365, differences = 1), max.lag = 600)
test <-periodogram(Max_temp_ts)

isSeasonal(Max_temp_ts)
isSeasonal(diff(Max_temp_ts, lag = 365, differences = 1))

source("https://raw.githubusercontent.com/iascchen/VisHealth/master/R/calendarHeat.R")
calendarHeat(ts_au_sydney$Date, ts_au_sydney$MaxTemp, color = "g2r", main = "calendar heat map of temperature in sydney")
```


```{r}
train_data<-results[1:1300,-c(9,20)]
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
std<-case_when(std==0 ~ 1,
         std !=0 ~ std) #If data series is constant, recode standard deviation to 1, to avoid dividing by 0
data <- scale(results[,-c(9,20)], center = mean, scale = std)

# Exactly copied generator function from Chollet and Allaire (p.195), 
# but setting 1 month steps and smaller batches for smaller data
# Also, allow which column of data is the one to be predicted to be an input
generator <- function(data, lookback, delay, min_index, max_index,
                      shuffle = FALSE, batch_size = 20, step = 1, predseries) {
  if (is.null(max_index)) max_index <- nrow(data) - delay - 1
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } else {
      if (i + batch_size >= max_index)
        i <<- min_index + lookback
      rows <- c(i:min(i+batch_size, max_index))
      i <<- i + length(rows)
}
    samples <- array(0, dim = c(length(rows),
                                lookback / step,
                                dim(data)[[-1]]))
    targets <- array(0, dim = c(length(rows)))
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback, rows[[j]],
                     length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,]
      targets[[j]] <- data[rows[[j]] + delay,predseries]
    }
    list(samples, targets)
  }
}
lookback<- 48 #4 years of past data used in each current prediction
step <- 1 #Do not skip observations (could set to higher value if you had extremely high frquency data, like for stock market data)
delay<- 1 #Predict 1 month ahead
batch_size <- 10 #draw 20 samples at a time
predser <- 6 #Target is the 6th series in the list, Industrial Production

#Training set looks at first 521 months
train_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = 1300,
  shuffle = TRUE,
  step = step,
  batch_size = batch_size,
  predseries = predser  
)
#Validation set looks at next 119 months
val_gen = generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1200,
  max_index = 1301,
   step = step,
  batch_size = batch_size,
  predseries = predser  
)
#Test set looks at remaining months (641-729)
test_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1300,
  max_index = NULL,
  step = step,
  batch_size = batch_size,
  predseries = predser    
)

val_steps <- ( 1300- 1200 - lookback) / batch_size
test_steps <- (nrow(data) - 1301 - lookback) / batch_size
densemodel <- keras_model_sequential() %>%
    layer_flatten(input_shape=c(lookback/step,dim(data)[-1])) %>%
    layer_dense(units=32,activation="relu") %>%
    layer_dense(units=1)


densemodel %>% compile(
    optimizer = "rmsprop",
    loss="mse"
)

history <- densemodel %>% fit_generator(
  train_gen,
  steps_per_epoch = 47,
  epochs = 20,
  validation_data = val_gen,
  validation_steps = val_steps
)

densemodel %>% save_model_hdf5("densetimeseries.h5")


sequence_generator <- function(start) {
  value <- start - 1
  function() {
    value <<- value + 1
    value
  }
}

gen <- sequence_generator(10)
gen()

```
```{r}
p<-autoplot(Max_temp_ts_train)+geom_line(data = var5.ts, aes(x = Date, y = data,color = "#65ADC2" ))+geom_point(data = var5.ts, aes(x = Date, y = data,color = "#65ADC2" ))+geom_line(data = var5.ts, aes(x = Date, y = data,color = "#233B43" ))+geom_point(data = var5.ts, aes(x = Date, y = data,color = "#233B43" ));p

var5.ts$model <- "VAR(1)"
var6.ts$model <- "VAR(2)"
lstm.ts$model <- "LSTM"
final <- rbind(orignal.ts, var5.ts, var6.ts,lstm.ts)
```
